{
    "train": true,
    "batch_size": 4,
    "pad_size": 32,
    "hidden_size": 768,
    "intermediate_size": 3072,
    "num_attention_heads": 12,
    "num_hidden_layers": 1,
    "full_model" : false,
    "use_lora": false,
    "use_adapter": true,
    "use_side": false,
    "use_side_only": false,
    "adapter_reduction_dim": 16,
    "non_linearity": "gelu_new"
}