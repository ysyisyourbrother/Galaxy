{
"do_train": true,
"do_eval": true,
"do_test": true,
"warmup_steps": 500,
"save_steps": 1000,
"model_name_or_path": "../../llm-models/t5/google-t5-large",
"tokenizer_name": "../../llm-models/t5/google-t5-large",
"save_total_limit": 0,
"per_device_train_batch_size": 32,
"per_device_eval_batch_size": 100,
"load_best_model_at_end": false,
"metric_for_best_model": "average_metrics",
"greater_is_better": true,
"evaluation_strategy": "epoch",
"non_linearity": "gelu_new",
"max_source_length": 128,
"learning_rate": 0.003,
"output_dir": "outputs/t5-large/side",
"split_validation_test": true,
"task_name": "cola",
"eval_dataset_name": "cola",
"test_dataset_name": "cola",
"num_train_epochs": 5,
"dataset_config_name": [
"en"
],
"eval_dataset_config_name": [
"en"
],
"test_dataset_config_name": [
"en"
],
"predict_with_generate": true,
"add_layer_norm_before_adapter": false,
"add_layer_norm_after_adapter": false,
"adapter_config_name": "adapter",
"train_side_ladder": false,
"task_reduction_factor": 8,
"unfreeze_lm_head": false,
"unfreeze_layer_norms": false,
"overwrite_output_dir": true,
"save_strategy": "no",
"compute_memory": true,
"compute_time": true,
"print_num_parameters": true,
"train_side_transformer": true,
"seed": 0,
"use_gate": "learnable",
"load_side_pretrained_weights": "fisher-v2",
"add_bias_sampling": true,
"create_side_lm": false,
"freeze_side_lm": false,
"add_residual_after": false,
"encoder_side_layers": [
1,
2,
3,
5,
6,
7,
9,
10,
11
],
"decoder_side_layers": [
1,
2,
3,
5,
6,
7,
9,
10,
11
]
}