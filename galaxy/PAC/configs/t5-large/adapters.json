{
"do_train": true,
"do_eval": true,
"do_test": true,
"warmup_steps": 500,
"save_steps": 1000,
"model_name_or_path": "../../llm-models/t5/google-t5-large",
"tokenizer_name": "../../llm-models/t5/google-t5-large",
"save_total_limit": 0,
"per_device_train_batch_size": 32,
"per_device_eval_batch_size": 100,
"load_best_model_at_end": false,
"metric_for_best_model": "average_metrics",
"greater_is_better": true,
"evaluation_strategy": "epoch",
"non_linearity": "gelu_new",
"max_source_length": 128,
"learning_rate": 0.0003,
"output_dir": "outputs/t5-large/adapters",
"split_validation_test": true,
"task_name": "cola",
"eval_dataset_name": "cola",
"test_dataset_name": "cola",
"num_train_epochs": 5,
"dataset_config_name": [
"en"
],
"eval_dataset_config_name": [
"en"
],
"test_dataset_config_name": [
"en"
],
"predict_with_generate": true,
"add_layer_norm_before_adapter": false,
"add_layer_norm_after_adapter": false,
"adapter_config_name": "adapter",
"train_task_adapters": true,
"task_reduction_factor": 16,
"unfreeze_lm_head": false,
"unfreeze_layer_norms": true,
"overwrite_output_dir": true,
"save_strategy": "no",
"compute_memory": true,
"compute_time": true,
"print_num_parameters": true,
"seed": 0,
"task_adapter_layers_encoder": null,
"task_adapter_layers_decoder": null,
"trainable_encoder_layers": null,
"trainable_decoder_layers": null
}